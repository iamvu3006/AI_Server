from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import io
import base64
from datetime import datetime
import os

from sse import init_sse

app = Flask(__name__)
CORS(app)

init_sse(app)

# Create folders for storing images
UPLOAD_FOLDER = 'received_images'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Global variables
model = None
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
IMG_SIZE = (256, 256)

def create_model():
    """Create ResNet18 with custom FC layer"""
    model = models.resnet18(weights=None)  # Updated API
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(512, 1)
    )
    return model

def get_transform():
    """Image preprocessing for inference"""
    return transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

def load_model():
    """Load the trained PyTorch model"""
    global model
    
    try:
        print("üì¶ Loading PyTorch ResNet18 model...")
        
        model = create_model()
        state_dict = torch.load('final_model.pth', map_location=device)
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()
        
        print(f"‚úÖ Model loaded successfully on {device}!")
        print(f"üìä Architecture: ResNet18 (custom FC layer)")
        print(f"üìä Parameters: {sum(p.numel() for p in model.parameters()):,}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error loading model: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def preprocess_image(image_data):
    """Preprocess image for model prediction"""
    try:
        if isinstance(image_data, bytes):
            image = Image.open(io.BytesIO(image_data))
        else:
            image = image_data
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        transform = get_transform()
        img_tensor = transform(image)
        img_tensor = img_tensor.unsqueeze(0)
        
        return img_tensor
        
    except Exception as e:
        print(f"‚ùå Error preprocessing: {str(e)}")
        return None

def predict_leaf(image_data):
    """Make prediction on leaf image"""
    try:
        img_tensor = preprocess_image(image_data)
        if img_tensor is None:
            return None
        
        img_tensor = img_tensor.to(device)
        
        with torch.no_grad():
            output = model(img_tensor)
            probability = torch.sigmoid(output).item()
        
        # Determine class
        if probability >= 0.5:
            predicted_class = 'healthy'
            confidence_score = probability
        else:
            predicted_class = 'diseased'
            confidence_score = 1.0 - probability
        
        # Create result
        top_predictions = [
            {'label': 'healthy', 'confidence': float(probability)},
            {'label': 'diseased', 'confidence': float(1.0 - probability)}
        ]
        top_predictions.sort(key=lambda x: x['confidence'], reverse=True)
        
        result = {
            'predicted_class': predicted_class,
            'confidence': confidence_score,
            'top_3_predictions': top_predictions,
            'timestamp': datetime.now().isoformat()
        }
        
        print(f"üçÉ {predicted_class} ({confidence_score:.2%}) | sigmoid: {probability:.4f}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Prediction error: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'device': str(device),
        'framework': 'PyTorch',
        'timestamp': datetime.now().isoformat()
    }), 200

@app.route('/predict', methods=['POST'])
def predict():
    try:
        if model is None:
            return jsonify({'error': 'Model not loaded'}), 503
        
        if 'image' not in request.files and 'image' not in request.form:
            return jsonify({'error': 'No image provided'}), 400
        
        if 'image' in request.files:
            image_data = request.files['image'].read()
        else:
            base64_data = request.form['image']
            if ',' in base64_data:
                base64_data = base64_data.split(',')[1]
            image_data = base64.b64decode(base64_data)
        
        result = predict_leaf(image_data)
        
        if result is None:
            return jsonify({'error': 'Prediction failed'}), 500
        
        return jsonify({'success': True, 'data': result}), 200
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/predict_esp32', methods=['POST'])
def predict_esp32():
    try:
        if model is None:
            return jsonify({'error': 'Model not ready'}), 503
        
        image_data = request.data
        if not image_data:
            return jsonify({'error': 'No image data'}), 400
        
        # Make prediction
        result = predict_leaf(image_data)
        if result is None:
            return jsonify({'error': 'Prediction failed'}), 500
        
        # Save image with timestamp and result
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        predicted_class = result['predicted_class']
        confidence = int(result['confidence'] * 100)
        
        filename = f"{timestamp}_{predicted_class}_{confidence}.jpg"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        with open(filepath, 'wb') as f:
            f.write(image_data)
        
        print(f"üíæ Saved: {filename}")
        
        # Return result with image filename
        return jsonify({
            'class': result['predicted_class'],
            'conf': round(result['confidence'], 2),
            'image': filename,  # Add filename to response
            'timestamp': result['timestamp']
        }), 200
        
    except Exception as e:
        print(f"‚ùå ESP32 error: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/classes', methods=['GET'])
def get_classes():
    return jsonify({
        'classes': ['diseased', 'healthy'],
        'total': 2
    }), 200

@app.route('/images/<filename>', methods=['GET'])
def get_image(filename):
    """Serve uploaded images"""
    try:
        return send_from_directory(UPLOAD_FOLDER, filename)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

@app.route('/images', methods=['GET'])
def list_images():
    """List all saved images"""
    try:
        files = os.listdir(UPLOAD_FOLDER)
        images = [f for f in files if f.endswith('.jpg')]
        images.sort(reverse=True)  # Newest first
        
        return jsonify({
            'images': images,
            'total': len(images)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("üöÄ Starting AI Server (PyTorch ResNet18)...")
    
    if torch.cuda.is_available():
        print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("‚ÑπÔ∏è  Running on CPU")
    
    if load_model():
        print("\n‚úÖ Server ready!")
        print("üì° http://0.0.0.0:5000")
        print("\nEndpoints:")
        print("  GET  /health")
        print("  POST /predict")
        print("  POST /predict_esp32")
        print("  GET  /classes")
        print("  GET  /images")
        print("  GET  /images/<filename>")
        print("  GET  /stream (SSE for dashboard)")
        print(f"\nüíæ Images saved to: {os.path.abspath(UPLOAD_FOLDER)}")
        print("\nüí° Model Info:")
        print("   Architecture: ResNet18 (custom FC with dropout)")
        print("   Output: Binary classification (diseased/healthy)")
        print("   Activation: Sigmoid (1 output neuron)")
        
        app.run(host='0.0.0.0', port=5000, debug=False)
    else:
        print("‚ùå Failed to load model")